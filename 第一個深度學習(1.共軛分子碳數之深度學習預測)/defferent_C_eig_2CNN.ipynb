{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "defferent_C_eig_2CNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMuWuolcPknlB3toxrD71ep",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yin-Tzu/predict_DA_reaction_product/blob/main/defferent_C_eig_2CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3t_mLBfsHAC"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dh-SAS_RsBHa",
        "outputId": "9b8be40a-623f-4443-838f-5ec6fdf82a7f"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow.keras import layers\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import time\r\n",
        "from sklearn import metrics\r\n",
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "import cv2\r\n",
        "import copy\r\n",
        "\r\n",
        "tStart = time.time()#計時開始\r\n",
        "datafile1 = u'./X_train.npy'\r\n",
        "datafile2 = u'./y_train.npy'\r\n",
        "datafile3 = u'./X_test.npy'\r\n",
        "datafile4 = u'./y_test.npy'\r\n",
        "datafile5 = u'./X_test2.npy'\r\n",
        "datafile6 = u'./y_test2.npy'\r\n",
        "X_train,y_train_label,X_test,y_test_label = np.load(datafile1), np.load(datafile2), np.load(datafile3), np.load(datafile4)\r\n",
        "print(X_train.shape,y_train_label.shape,X_test.shape,y_test_label.shape)\r\n",
        "X_2,y_2 = np.load(datafile5), np.load(datafile6)\r\n",
        "\r\n",
        "y_Test2 = tf.keras.utils.to_categorical(y_2)\r\n",
        "y_TrainOneHot = tf.keras.utils.to_categorical(y_train_label)  # One-Hot编码\r\n",
        "y_TestOneHot = tf.keras.utils.to_categorical(y_test_label)\r\n",
        "\r\n",
        "model = tf.keras.models.Sequential()  # 调用Sequential模型\r\n",
        "model.add(layers.Conv2D(input_shape=(2,3, 1), filters=16, kernel_size=(3,3), kernel_initializer='TruncatedNormal', strides=1, padding='same', activation='relu', name='conv1')) # 只需要input_shape改變(2,3,1)(4,3,1)(6,3,1)... \r\n",
        "model.add(layers.AveragePooling2D(pool_size=(2,2), strides=2, padding='same', name='pool1'))  # AveragePooling2D\r\n",
        "model.add(layers.Flatten(name='flatten'))\r\n",
        "model.add(layers.Dense(units=64, kernel_initializer='TruncatedNormal', activation='relu'))\r\n",
        "model.add(layers.Dense(units=2,kernel_initializer='TruncatedNormal', activation='softmax'))  # 兩個C的output需改成units=2，其他事units=3\r\n",
        "\r\n",
        "print(model.summary())\r\n",
        "\r\n",
        "# 模型的训练 编译模型\r\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\r\n",
        "\r\n",
        "# 训练模型\r\n",
        "train_history = model.fit(x=X_train, y=y_TrainOneHot,validation_split=0.25, epochs=200, batch_size=2, verbose=2)  # ,validation_data=(X_valid, y_ValidOneHot), callbacks=[es])#,validation_split=0.25  callbacks=[tensorboard_callback])  # verbose日志显示，0为不在标准输出流输出日志信息，1为输出进度条记录，2为每个epoch输出一行记录\r\n",
        "# 查看训练过程，之前的训练步骤的值都保存在这里面。这里共有loss,accuracy,val_loss,val_accuracy四个参数\r\n",
        "print(train_history.history)\r\n",
        "\r\n",
        "\r\n",
        "#測試的loss及準確率\r\n",
        "scores = model.evaluate(X_test,y_TestOneHot)\r\n",
        "print('loss, accuracy=',scores) #显示测试准确率[1]\r\n",
        "\r\n",
        "scores2 = model.evaluate(X_2,y_Test2)\r\n",
        "print('loss, accuracy=',scores) #显示测试准确率[1]\r\n",
        "\r\n",
        "prediction = model.predict_classes(X_test)\r\n",
        "prediction2 = model.predict_classes(X_2)\r\n",
        "# 返回预测属于某标签的概率\r\n",
        "y_score = model.predict_proba(X_2)\r\n",
        "#print(y_score)\r\n",
        "\r\n",
        "# 將模型儲存至 HDF5 檔案中\r\n",
        "model.save('eig_model.h5')  # creates a HDF5 file 'my_model.h5'\r\n",
        "\r\n",
        "tEnd = time.time()#計時結束\r\n",
        "#列印結果\r\n",
        "print(\"It cost %f sec\" % (tEnd - tStart))  #會自動做近位\r\n",
        "print(tEnd - tStart)  #原型長這樣\r\n",
        "\r\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(80, 2, 3, 1) (80,) (20, 2, 3, 1) (20,)\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1 (Conv2D)               (None, 2, 3, 16)          160       \n",
            "_________________________________________________________________\n",
            "pool1 (AveragePooling2D)     (None, 1, 2, 16)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 2,402\n",
            "Trainable params: 2,402\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "30/30 - 1s - loss: 0.6905 - accuracy: 0.5167 - val_loss: 0.6866 - val_accuracy: 0.4500\n",
            "Epoch 2/200\n",
            "30/30 - 0s - loss: 0.6628 - accuracy: 0.6333 - val_loss: 0.6424 - val_accuracy: 0.7000\n",
            "Epoch 3/200\n",
            "30/30 - 0s - loss: 0.5630 - accuracy: 0.9333 - val_loss: 0.5077 - val_accuracy: 1.0000\n",
            "Epoch 4/200\n",
            "30/30 - 0s - loss: 0.3728 - accuracy: 1.0000 - val_loss: 0.3071 - val_accuracy: 1.0000\n",
            "Epoch 5/200\n",
            "30/30 - 0s - loss: 0.1898 - accuracy: 1.0000 - val_loss: 0.1477 - val_accuracy: 1.0000\n",
            "Epoch 6/200\n",
            "30/30 - 0s - loss: 0.0850 - accuracy: 1.0000 - val_loss: 0.0655 - val_accuracy: 1.0000\n",
            "Epoch 7/200\n",
            "30/30 - 0s - loss: 0.0378 - accuracy: 1.0000 - val_loss: 0.0355 - val_accuracy: 1.0000\n",
            "Epoch 8/200\n",
            "30/30 - 0s - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.0209 - val_accuracy: 1.0000\n",
            "Epoch 9/200\n",
            "30/30 - 0s - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 1.0000\n",
            "Epoch 10/200\n",
            "30/30 - 0s - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
            "Epoch 11/200\n",
            "30/30 - 0s - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
            "Epoch 12/200\n",
            "30/30 - 0s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
            "Epoch 13/200\n",
            "30/30 - 0s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
            "Epoch 14/200\n",
            "30/30 - 0s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
            "Epoch 15/200\n",
            "30/30 - 0s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
            "Epoch 16/200\n",
            "30/30 - 0s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 17/200\n",
            "30/30 - 0s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 18/200\n",
            "30/30 - 0s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 19/200\n",
            "30/30 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 20/200\n",
            "30/30 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 21/200\n",
            "30/30 - 0s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 22/200\n",
            "30/30 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 23/200\n",
            "30/30 - 0s - loss: 9.5623e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 24/200\n",
            "30/30 - 0s - loss: 8.6649e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 25/200\n",
            "30/30 - 0s - loss: 7.8959e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 26/200\n",
            "30/30 - 0s - loss: 7.1921e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 27/200\n",
            "30/30 - 0s - loss: 6.5975e-04 - accuracy: 1.0000 - val_loss: 9.4620e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/200\n",
            "30/30 - 0s - loss: 6.0724e-04 - accuracy: 1.0000 - val_loss: 8.7484e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/200\n",
            "30/30 - 0s - loss: 5.6108e-04 - accuracy: 1.0000 - val_loss: 8.0143e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/200\n",
            "30/30 - 0s - loss: 5.1916e-04 - accuracy: 1.0000 - val_loss: 7.4028e-04 - val_accuracy: 1.0000\n",
            "Epoch 31/200\n",
            "30/30 - 0s - loss: 4.8080e-04 - accuracy: 1.0000 - val_loss: 6.9497e-04 - val_accuracy: 1.0000\n",
            "Epoch 32/200\n",
            "30/30 - 0s - loss: 4.4795e-04 - accuracy: 1.0000 - val_loss: 6.4954e-04 - val_accuracy: 1.0000\n",
            "Epoch 33/200\n",
            "30/30 - 0s - loss: 4.1761e-04 - accuracy: 1.0000 - val_loss: 6.1228e-04 - val_accuracy: 1.0000\n",
            "Epoch 34/200\n",
            "30/30 - 0s - loss: 3.9082e-04 - accuracy: 1.0000 - val_loss: 5.6892e-04 - val_accuracy: 1.0000\n",
            "Epoch 35/200\n",
            "30/30 - 0s - loss: 3.6606e-04 - accuracy: 1.0000 - val_loss: 5.3307e-04 - val_accuracy: 1.0000\n",
            "Epoch 36/200\n",
            "30/30 - 0s - loss: 3.4341e-04 - accuracy: 1.0000 - val_loss: 5.0121e-04 - val_accuracy: 1.0000\n",
            "Epoch 37/200\n",
            "30/30 - 0s - loss: 3.2254e-04 - accuracy: 1.0000 - val_loss: 4.7303e-04 - val_accuracy: 1.0000\n",
            "Epoch 38/200\n",
            "30/30 - 0s - loss: 3.0395e-04 - accuracy: 1.0000 - val_loss: 4.4492e-04 - val_accuracy: 1.0000\n",
            "Epoch 39/200\n",
            "30/30 - 0s - loss: 2.8670e-04 - accuracy: 1.0000 - val_loss: 4.2184e-04 - val_accuracy: 1.0000\n",
            "Epoch 40/200\n",
            "30/30 - 0s - loss: 2.7051e-04 - accuracy: 1.0000 - val_loss: 4.0042e-04 - val_accuracy: 1.0000\n",
            "Epoch 41/200\n",
            "30/30 - 0s - loss: 2.5602e-04 - accuracy: 1.0000 - val_loss: 3.7917e-04 - val_accuracy: 1.0000\n",
            "Epoch 42/200\n",
            "30/30 - 0s - loss: 2.4266e-04 - accuracy: 1.0000 - val_loss: 3.5660e-04 - val_accuracy: 1.0000\n",
            "Epoch 43/200\n",
            "30/30 - 0s - loss: 2.2979e-04 - accuracy: 1.0000 - val_loss: 3.4131e-04 - val_accuracy: 1.0000\n",
            "Epoch 44/200\n",
            "30/30 - 0s - loss: 2.1816e-04 - accuracy: 1.0000 - val_loss: 3.2386e-04 - val_accuracy: 1.0000\n",
            "Epoch 45/200\n",
            "30/30 - 0s - loss: 2.0739e-04 - accuracy: 1.0000 - val_loss: 3.0862e-04 - val_accuracy: 1.0000\n",
            "Epoch 46/200\n",
            "30/30 - 0s - loss: 1.9744e-04 - accuracy: 1.0000 - val_loss: 2.9297e-04 - val_accuracy: 1.0000\n",
            "Epoch 47/200\n",
            "30/30 - 0s - loss: 1.8792e-04 - accuracy: 1.0000 - val_loss: 2.8078e-04 - val_accuracy: 1.0000\n",
            "Epoch 48/200\n",
            "30/30 - 0s - loss: 1.7934e-04 - accuracy: 1.0000 - val_loss: 2.6767e-04 - val_accuracy: 1.0000\n",
            "Epoch 49/200\n",
            "30/30 - 0s - loss: 1.7095e-04 - accuracy: 1.0000 - val_loss: 2.5592e-04 - val_accuracy: 1.0000\n",
            "Epoch 50/200\n",
            "30/30 - 0s - loss: 1.6322e-04 - accuracy: 1.0000 - val_loss: 2.4543e-04 - val_accuracy: 1.0000\n",
            "Epoch 51/200\n",
            "30/30 - 0s - loss: 1.5620e-04 - accuracy: 1.0000 - val_loss: 2.3368e-04 - val_accuracy: 1.0000\n",
            "Epoch 52/200\n",
            "30/30 - 0s - loss: 1.4932e-04 - accuracy: 1.0000 - val_loss: 2.2417e-04 - val_accuracy: 1.0000\n",
            "Epoch 53/200\n",
            "30/30 - 0s - loss: 1.4301e-04 - accuracy: 1.0000 - val_loss: 2.1574e-04 - val_accuracy: 1.0000\n",
            "Epoch 54/200\n",
            "30/30 - 0s - loss: 1.3697e-04 - accuracy: 1.0000 - val_loss: 2.0642e-04 - val_accuracy: 1.0000\n",
            "Epoch 55/200\n",
            "30/30 - 0s - loss: 1.3127e-04 - accuracy: 1.0000 - val_loss: 1.9836e-04 - val_accuracy: 1.0000\n",
            "Epoch 56/200\n",
            "30/30 - 0s - loss: 1.2597e-04 - accuracy: 1.0000 - val_loss: 1.9012e-04 - val_accuracy: 1.0000\n",
            "Epoch 57/200\n",
            "30/30 - 0s - loss: 1.2097e-04 - accuracy: 1.0000 - val_loss: 1.8282e-04 - val_accuracy: 1.0000\n",
            "Epoch 58/200\n",
            "30/30 - 0s - loss: 1.1624e-04 - accuracy: 1.0000 - val_loss: 1.7512e-04 - val_accuracy: 1.0000\n",
            "Epoch 59/200\n",
            "30/30 - 0s - loss: 1.1164e-04 - accuracy: 1.0000 - val_loss: 1.6877e-04 - val_accuracy: 1.0000\n",
            "Epoch 60/200\n",
            "30/30 - 0s - loss: 1.0743e-04 - accuracy: 1.0000 - val_loss: 1.6205e-04 - val_accuracy: 1.0000\n",
            "Epoch 61/200\n",
            "30/30 - 0s - loss: 1.0334e-04 - accuracy: 1.0000 - val_loss: 1.5664e-04 - val_accuracy: 1.0000\n",
            "Epoch 62/200\n",
            "30/30 - 0s - loss: 9.9545e-05 - accuracy: 1.0000 - val_loss: 1.5131e-04 - val_accuracy: 1.0000\n",
            "Epoch 63/200\n",
            "30/30 - 0s - loss: 9.5885e-05 - accuracy: 1.0000 - val_loss: 1.4497e-04 - val_accuracy: 1.0000\n",
            "Epoch 64/200\n",
            "30/30 - 0s - loss: 9.2379e-05 - accuracy: 1.0000 - val_loss: 1.3984e-04 - val_accuracy: 1.0000\n",
            "Epoch 65/200\n",
            "30/30 - 0s - loss: 8.9058e-05 - accuracy: 1.0000 - val_loss: 1.3545e-04 - val_accuracy: 1.0000\n",
            "Epoch 66/200\n",
            "30/30 - 0s - loss: 8.5957e-05 - accuracy: 1.0000 - val_loss: 1.3110e-04 - val_accuracy: 1.0000\n",
            "Epoch 67/200\n",
            "30/30 - 0s - loss: 8.2939e-05 - accuracy: 1.0000 - val_loss: 1.2616e-04 - val_accuracy: 1.0000\n",
            "Epoch 68/200\n",
            "30/30 - 0s - loss: 8.0060e-05 - accuracy: 1.0000 - val_loss: 1.2184e-04 - val_accuracy: 1.0000\n",
            "Epoch 69/200\n",
            "30/30 - 0s - loss: 7.7349e-05 - accuracy: 1.0000 - val_loss: 1.1784e-04 - val_accuracy: 1.0000\n",
            "Epoch 70/200\n",
            "30/30 - 0s - loss: 7.4712e-05 - accuracy: 1.0000 - val_loss: 1.1433e-04 - val_accuracy: 1.0000\n",
            "Epoch 71/200\n",
            "30/30 - 0s - loss: 7.2247e-05 - accuracy: 1.0000 - val_loss: 1.1041e-04 - val_accuracy: 1.0000\n",
            "Epoch 72/200\n",
            "30/30 - 0s - loss: 6.9909e-05 - accuracy: 1.0000 - val_loss: 1.0656e-04 - val_accuracy: 1.0000\n",
            "Epoch 73/200\n",
            "30/30 - 0s - loss: 6.7559e-05 - accuracy: 1.0000 - val_loss: 1.0393e-04 - val_accuracy: 1.0000\n",
            "Epoch 74/200\n",
            "30/30 - 0s - loss: 6.5445e-05 - accuracy: 1.0000 - val_loss: 1.0012e-04 - val_accuracy: 1.0000\n",
            "Epoch 75/200\n",
            "30/30 - 0s - loss: 6.3323e-05 - accuracy: 1.0000 - val_loss: 9.7194e-05 - val_accuracy: 1.0000\n",
            "Epoch 76/200\n",
            "30/30 - 0s - loss: 6.1307e-05 - accuracy: 1.0000 - val_loss: 9.4644e-05 - val_accuracy: 1.0000\n",
            "Epoch 77/200\n",
            "30/30 - 0s - loss: 5.9443e-05 - accuracy: 1.0000 - val_loss: 9.1187e-05 - val_accuracy: 1.0000\n",
            "Epoch 78/200\n",
            "30/30 - 0s - loss: 5.7532e-05 - accuracy: 1.0000 - val_loss: 8.8392e-05 - val_accuracy: 1.0000\n",
            "Epoch 79/200\n",
            "30/30 - 0s - loss: 5.5806e-05 - accuracy: 1.0000 - val_loss: 8.6116e-05 - val_accuracy: 1.0000\n",
            "Epoch 80/200\n",
            "30/30 - 0s - loss: 5.4087e-05 - accuracy: 1.0000 - val_loss: 8.3559e-05 - val_accuracy: 1.0000\n",
            "Epoch 81/200\n",
            "30/30 - 0s - loss: 5.2474e-05 - accuracy: 1.0000 - val_loss: 8.0931e-05 - val_accuracy: 1.0000\n",
            "Epoch 82/200\n",
            "30/30 - 0s - loss: 5.0914e-05 - accuracy: 1.0000 - val_loss: 7.8464e-05 - val_accuracy: 1.0000\n",
            "Epoch 83/200\n",
            "30/30 - 0s - loss: 4.9379e-05 - accuracy: 1.0000 - val_loss: 7.6294e-05 - val_accuracy: 1.0000\n",
            "Epoch 84/200\n",
            "30/30 - 0s - loss: 4.7948e-05 - accuracy: 1.0000 - val_loss: 7.4042e-05 - val_accuracy: 1.0000\n",
            "Epoch 85/200\n",
            "30/30 - 0s - loss: 4.6554e-05 - accuracy: 1.0000 - val_loss: 7.1962e-05 - val_accuracy: 1.0000\n",
            "Epoch 86/200\n",
            "30/30 - 0s - loss: 4.5219e-05 - accuracy: 1.0000 - val_loss: 6.9816e-05 - val_accuracy: 1.0000\n",
            "Epoch 87/200\n",
            "30/30 - 0s - loss: 4.3921e-05 - accuracy: 1.0000 - val_loss: 6.7849e-05 - val_accuracy: 1.0000\n",
            "Epoch 88/200\n",
            "30/30 - 0s - loss: 4.2668e-05 - accuracy: 1.0000 - val_loss: 6.6091e-05 - val_accuracy: 1.0000\n",
            "Epoch 89/200\n",
            "30/30 - 0s - loss: 4.1462e-05 - accuracy: 1.0000 - val_loss: 6.4268e-05 - val_accuracy: 1.0000\n",
            "Epoch 90/200\n",
            "30/30 - 0s - loss: 4.0351e-05 - accuracy: 1.0000 - val_loss: 6.2581e-05 - val_accuracy: 1.0000\n",
            "Epoch 91/200\n",
            "30/30 - 0s - loss: 3.9201e-05 - accuracy: 1.0000 - val_loss: 6.0900e-05 - val_accuracy: 1.0000\n",
            "Epoch 92/200\n",
            "30/30 - 0s - loss: 3.8146e-05 - accuracy: 1.0000 - val_loss: 5.8940e-05 - val_accuracy: 1.0000\n",
            "Epoch 93/200\n",
            "30/30 - 0s - loss: 3.7075e-05 - accuracy: 1.0000 - val_loss: 5.7599e-05 - val_accuracy: 1.0000\n",
            "Epoch 94/200\n",
            "30/30 - 0s - loss: 3.6096e-05 - accuracy: 1.0000 - val_loss: 5.6115e-05 - val_accuracy: 1.0000\n",
            "Epoch 95/200\n",
            "30/30 - 0s - loss: 3.5110e-05 - accuracy: 1.0000 - val_loss: 5.4565e-05 - val_accuracy: 1.0000\n",
            "Epoch 96/200\n",
            "30/30 - 0s - loss: 3.4180e-05 - accuracy: 1.0000 - val_loss: 5.3087e-05 - val_accuracy: 1.0000\n",
            "Epoch 97/200\n",
            "30/30 - 0s - loss: 3.3265e-05 - accuracy: 1.0000 - val_loss: 5.1865e-05 - val_accuracy: 1.0000\n",
            "Epoch 98/200\n",
            "30/30 - 0s - loss: 3.2398e-05 - accuracy: 1.0000 - val_loss: 5.0447e-05 - val_accuracy: 1.0000\n",
            "Epoch 99/200\n",
            "30/30 - 0s - loss: 3.1566e-05 - accuracy: 1.0000 - val_loss: 4.9082e-05 - val_accuracy: 1.0000\n",
            "Epoch 100/200\n",
            "30/30 - 0s - loss: 3.0716e-05 - accuracy: 1.0000 - val_loss: 4.7968e-05 - val_accuracy: 1.0000\n",
            "Epoch 101/200\n",
            "30/30 - 0s - loss: 2.9953e-05 - accuracy: 1.0000 - val_loss: 4.6871e-05 - val_accuracy: 1.0000\n",
            "Epoch 102/200\n",
            "30/30 - 0s - loss: 2.9178e-05 - accuracy: 1.0000 - val_loss: 4.5554e-05 - val_accuracy: 1.0000\n",
            "Epoch 103/200\n",
            "30/30 - 0s - loss: 2.8433e-05 - accuracy: 1.0000 - val_loss: 4.4415e-05 - val_accuracy: 1.0000\n",
            "Epoch 104/200\n",
            "30/30 - 0s - loss: 2.7716e-05 - accuracy: 1.0000 - val_loss: 4.3426e-05 - val_accuracy: 1.0000\n",
            "Epoch 105/200\n",
            "30/30 - 0s - loss: 2.7018e-05 - accuracy: 1.0000 - val_loss: 4.2222e-05 - val_accuracy: 1.0000\n",
            "Epoch 106/200\n",
            "30/30 - 0s - loss: 2.6339e-05 - accuracy: 1.0000 - val_loss: 4.1328e-05 - val_accuracy: 1.0000\n",
            "Epoch 107/200\n",
            "30/30 - 0s - loss: 2.5695e-05 - accuracy: 1.0000 - val_loss: 4.0273e-05 - val_accuracy: 1.0000\n",
            "Epoch 108/200\n",
            "30/30 - 0s - loss: 2.5061e-05 - accuracy: 1.0000 - val_loss: 3.9200e-05 - val_accuracy: 1.0000\n",
            "Epoch 109/200\n",
            "30/30 - 0s - loss: 2.4441e-05 - accuracy: 1.0000 - val_loss: 3.8259e-05 - val_accuracy: 1.0000\n",
            "Epoch 110/200\n",
            "30/30 - 0s - loss: 2.3841e-05 - accuracy: 1.0000 - val_loss: 3.7442e-05 - val_accuracy: 1.0000\n",
            "Epoch 111/200\n",
            "30/30 - 0s - loss: 2.3253e-05 - accuracy: 1.0000 - val_loss: 3.6530e-05 - val_accuracy: 1.0000\n",
            "Epoch 112/200\n",
            "30/30 - 0s - loss: 2.2697e-05 - accuracy: 1.0000 - val_loss: 3.5702e-05 - val_accuracy: 1.0000\n",
            "Epoch 113/200\n",
            "30/30 - 0s - loss: 2.2159e-05 - accuracy: 1.0000 - val_loss: 3.4748e-05 - val_accuracy: 1.0000\n",
            "Epoch 114/200\n",
            "30/30 - 0s - loss: 2.1624e-05 - accuracy: 1.0000 - val_loss: 3.3914e-05 - val_accuracy: 1.0000\n",
            "Epoch 115/200\n",
            "30/30 - 0s - loss: 2.1106e-05 - accuracy: 1.0000 - val_loss: 3.3187e-05 - val_accuracy: 1.0000\n",
            "Epoch 116/200\n",
            "30/30 - 0s - loss: 2.0601e-05 - accuracy: 1.0000 - val_loss: 3.2448e-05 - val_accuracy: 1.0000\n",
            "Epoch 117/200\n",
            "30/30 - 0s - loss: 2.0124e-05 - accuracy: 1.0000 - val_loss: 3.1631e-05 - val_accuracy: 1.0000\n",
            "Epoch 118/200\n",
            "30/30 - 0s - loss: 1.9651e-05 - accuracy: 1.0000 - val_loss: 3.0970e-05 - val_accuracy: 1.0000\n",
            "Epoch 119/200\n",
            "30/30 - 0s - loss: 1.9188e-05 - accuracy: 1.0000 - val_loss: 3.0219e-05 - val_accuracy: 1.0000\n",
            "Epoch 120/200\n",
            "30/30 - 0s - loss: 1.8751e-05 - accuracy: 1.0000 - val_loss: 2.9492e-05 - val_accuracy: 1.0000\n",
            "Epoch 121/200\n",
            "30/30 - 0s - loss: 1.8318e-05 - accuracy: 1.0000 - val_loss: 2.8818e-05 - val_accuracy: 1.0000\n",
            "Epoch 122/200\n",
            "30/30 - 0s - loss: 1.7889e-05 - accuracy: 1.0000 - val_loss: 2.8222e-05 - val_accuracy: 1.0000\n",
            "Epoch 123/200\n",
            "30/30 - 0s - loss: 1.7492e-05 - accuracy: 1.0000 - val_loss: 2.7596e-05 - val_accuracy: 1.0000\n",
            "Epoch 124/200\n",
            "30/30 - 0s - loss: 1.7086e-05 - accuracy: 1.0000 - val_loss: 2.6941e-05 - val_accuracy: 1.0000\n",
            "Epoch 125/200\n",
            "30/30 - 0s - loss: 1.6701e-05 - accuracy: 1.0000 - val_loss: 2.6416e-05 - val_accuracy: 1.0000\n",
            "Epoch 126/200\n",
            "30/30 - 0s - loss: 1.6316e-05 - accuracy: 1.0000 - val_loss: 2.5796e-05 - val_accuracy: 1.0000\n",
            "Epoch 127/200\n",
            "30/30 - 0s - loss: 1.5952e-05 - accuracy: 1.0000 - val_loss: 2.5200e-05 - val_accuracy: 1.0000\n",
            "Epoch 128/200\n",
            "30/30 - 0s - loss: 1.5588e-05 - accuracy: 1.0000 - val_loss: 2.4670e-05 - val_accuracy: 1.0000\n",
            "Epoch 129/200\n",
            "30/30 - 0s - loss: 1.5247e-05 - accuracy: 1.0000 - val_loss: 2.4115e-05 - val_accuracy: 1.0000\n",
            "Epoch 130/200\n",
            "30/30 - 0s - loss: 1.4905e-05 - accuracy: 1.0000 - val_loss: 2.3579e-05 - val_accuracy: 1.0000\n",
            "Epoch 131/200\n",
            "30/30 - 0s - loss: 1.4579e-05 - accuracy: 1.0000 - val_loss: 2.3019e-05 - val_accuracy: 1.0000\n",
            "Epoch 132/200\n",
            "30/30 - 0s - loss: 1.4259e-05 - accuracy: 1.0000 - val_loss: 2.2613e-05 - val_accuracy: 1.0000\n",
            "Epoch 133/200\n",
            "30/30 - 0s - loss: 1.3937e-05 - accuracy: 1.0000 - val_loss: 2.2166e-05 - val_accuracy: 1.0000\n",
            "Epoch 134/200\n",
            "30/30 - 0s - loss: 1.3645e-05 - accuracy: 1.0000 - val_loss: 2.1612e-05 - val_accuracy: 1.0000\n",
            "Epoch 135/200\n",
            "30/30 - 0s - loss: 1.3349e-05 - accuracy: 1.0000 - val_loss: 2.1237e-05 - val_accuracy: 1.0000\n",
            "Epoch 136/200\n",
            "30/30 - 0s - loss: 1.3049e-05 - accuracy: 1.0000 - val_loss: 2.0694e-05 - val_accuracy: 1.0000\n",
            "Epoch 137/200\n",
            "30/30 - 0s - loss: 1.2763e-05 - accuracy: 1.0000 - val_loss: 2.0295e-05 - val_accuracy: 1.0000\n",
            "Epoch 138/200\n",
            "30/30 - 0s - loss: 1.2497e-05 - accuracy: 1.0000 - val_loss: 1.9848e-05 - val_accuracy: 1.0000\n",
            "Epoch 139/200\n",
            "30/30 - 0s - loss: 1.2233e-05 - accuracy: 1.0000 - val_loss: 1.9401e-05 - val_accuracy: 1.0000\n",
            "Epoch 140/200\n",
            "30/30 - 0s - loss: 1.1959e-05 - accuracy: 1.0000 - val_loss: 1.9002e-05 - val_accuracy: 1.0000\n",
            "Epoch 141/200\n",
            "30/30 - 0s - loss: 1.1702e-05 - accuracy: 1.0000 - val_loss: 1.8644e-05 - val_accuracy: 1.0000\n",
            "Epoch 142/200\n",
            "30/30 - 0s - loss: 1.1456e-05 - accuracy: 1.0000 - val_loss: 1.8274e-05 - val_accuracy: 1.0000\n",
            "Epoch 143/200\n",
            "30/30 - 0s - loss: 1.1216e-05 - accuracy: 1.0000 - val_loss: 1.7863e-05 - val_accuracy: 1.0000\n",
            "Epoch 144/200\n",
            "30/30 - 0s - loss: 1.0977e-05 - accuracy: 1.0000 - val_loss: 1.7535e-05 - val_accuracy: 1.0000\n",
            "Epoch 145/200\n",
            "30/30 - 0s - loss: 1.0751e-05 - accuracy: 1.0000 - val_loss: 1.7148e-05 - val_accuracy: 1.0000\n",
            "Epoch 146/200\n",
            "30/30 - 0s - loss: 1.0516e-05 - accuracy: 1.0000 - val_loss: 1.6820e-05 - val_accuracy: 1.0000\n",
            "Epoch 147/200\n",
            "30/30 - 0s - loss: 1.0317e-05 - accuracy: 1.0000 - val_loss: 1.6355e-05 - val_accuracy: 1.0000\n",
            "Epoch 148/200\n",
            "30/30 - 0s - loss: 1.0085e-05 - accuracy: 1.0000 - val_loss: 1.6093e-05 - val_accuracy: 1.0000\n",
            "Epoch 149/200\n",
            "30/30 - 0s - loss: 9.8804e-06 - accuracy: 1.0000 - val_loss: 1.5729e-05 - val_accuracy: 1.0000\n",
            "Epoch 150/200\n",
            "30/30 - 0s - loss: 9.6718e-06 - accuracy: 1.0000 - val_loss: 1.5443e-05 - val_accuracy: 1.0000\n",
            "Epoch 151/200\n",
            "30/30 - 0s - loss: 9.4751e-06 - accuracy: 1.0000 - val_loss: 1.5127e-05 - val_accuracy: 1.0000\n",
            "Epoch 152/200\n",
            "30/30 - 0s - loss: 9.2685e-06 - accuracy: 1.0000 - val_loss: 1.4823e-05 - val_accuracy: 1.0000\n",
            "Epoch 153/200\n",
            "30/30 - 0s - loss: 9.0837e-06 - accuracy: 1.0000 - val_loss: 1.4514e-05 - val_accuracy: 1.0000\n",
            "Epoch 154/200\n",
            "30/30 - 0s - loss: 8.8969e-06 - accuracy: 1.0000 - val_loss: 1.4156e-05 - val_accuracy: 1.0000\n",
            "Epoch 155/200\n",
            "30/30 - 0s - loss: 8.7181e-06 - accuracy: 1.0000 - val_loss: 1.3900e-05 - val_accuracy: 1.0000\n",
            "Epoch 156/200\n",
            "30/30 - 0s - loss: 8.5413e-06 - accuracy: 1.0000 - val_loss: 1.3637e-05 - val_accuracy: 1.0000\n",
            "Epoch 157/200\n",
            "30/30 - 0s - loss: 8.3684e-06 - accuracy: 1.0000 - val_loss: 1.3417e-05 - val_accuracy: 1.0000\n",
            "Epoch 158/200\n",
            "30/30 - 0s - loss: 8.1916e-06 - accuracy: 1.0000 - val_loss: 1.3155e-05 - val_accuracy: 1.0000\n",
            "Epoch 159/200\n",
            "30/30 - 0s - loss: 8.0307e-06 - accuracy: 1.0000 - val_loss: 1.2851e-05 - val_accuracy: 1.0000\n",
            "Epoch 160/200\n",
            "30/30 - 0s - loss: 7.8638e-06 - accuracy: 1.0000 - val_loss: 1.2624e-05 - val_accuracy: 1.0000\n",
            "Epoch 161/200\n",
            "30/30 - 0s - loss: 7.7227e-06 - accuracy: 1.0000 - val_loss: 1.2362e-05 - val_accuracy: 1.0000\n",
            "Epoch 162/200\n",
            "30/30 - 0s - loss: 7.5618e-06 - accuracy: 1.0000 - val_loss: 1.2123e-05 - val_accuracy: 1.0000\n",
            "Epoch 163/200\n",
            "30/30 - 0s - loss: 7.4068e-06 - accuracy: 1.0000 - val_loss: 1.1903e-05 - val_accuracy: 1.0000\n",
            "Epoch 164/200\n",
            "30/30 - 0s - loss: 7.2658e-06 - accuracy: 1.0000 - val_loss: 1.1611e-05 - val_accuracy: 1.0000\n",
            "Epoch 165/200\n",
            "30/30 - 0s - loss: 7.1128e-06 - accuracy: 1.0000 - val_loss: 1.1396e-05 - val_accuracy: 1.0000\n",
            "Epoch 166/200\n",
            "30/30 - 0s - loss: 6.9737e-06 - accuracy: 1.0000 - val_loss: 1.1152e-05 - val_accuracy: 1.0000\n",
            "Epoch 167/200\n",
            "30/30 - 0s - loss: 6.8346e-06 - accuracy: 1.0000 - val_loss: 1.0961e-05 - val_accuracy: 1.0000\n",
            "Epoch 168/200\n",
            "30/30 - 0s - loss: 6.7134e-06 - accuracy: 1.0000 - val_loss: 1.0741e-05 - val_accuracy: 1.0000\n",
            "Epoch 169/200\n",
            "30/30 - 0s - loss: 6.5605e-06 - accuracy: 1.0000 - val_loss: 1.0550e-05 - val_accuracy: 1.0000\n",
            "Epoch 170/200\n",
            "30/30 - 0s - loss: 6.4353e-06 - accuracy: 1.0000 - val_loss: 1.0371e-05 - val_accuracy: 1.0000\n",
            "Epoch 171/200\n",
            "30/30 - 0s - loss: 6.3181e-06 - accuracy: 1.0000 - val_loss: 1.0186e-05 - val_accuracy: 1.0000\n",
            "Epoch 172/200\n",
            "30/30 - 0s - loss: 6.1929e-06 - accuracy: 1.0000 - val_loss: 9.9300e-06 - val_accuracy: 1.0000\n",
            "Epoch 173/200\n",
            "30/30 - 0s - loss: 6.0677e-06 - accuracy: 1.0000 - val_loss: 9.7691e-06 - val_accuracy: 1.0000\n",
            "Epoch 174/200\n",
            "30/30 - 0s - loss: 5.9465e-06 - accuracy: 1.0000 - val_loss: 9.5724e-06 - val_accuracy: 1.0000\n",
            "Epoch 175/200\n",
            "30/30 - 0s - loss: 5.8392e-06 - accuracy: 1.0000 - val_loss: 9.3817e-06 - val_accuracy: 1.0000\n",
            "Epoch 176/200\n",
            "30/30 - 0s - loss: 5.7200e-06 - accuracy: 1.0000 - val_loss: 9.1850e-06 - val_accuracy: 1.0000\n",
            "Epoch 177/200\n",
            "30/30 - 0s - loss: 5.5988e-06 - accuracy: 1.0000 - val_loss: 9.0598e-06 - val_accuracy: 1.0000\n",
            "Epoch 178/200\n",
            "30/30 - 0s - loss: 5.5035e-06 - accuracy: 1.0000 - val_loss: 8.8631e-06 - val_accuracy: 1.0000\n",
            "Epoch 179/200\n",
            "30/30 - 0s - loss: 5.4002e-06 - accuracy: 1.0000 - val_loss: 8.7022e-06 - val_accuracy: 1.0000\n",
            "Epoch 180/200\n",
            "30/30 - 0s - loss: 5.2849e-06 - accuracy: 1.0000 - val_loss: 8.5294e-06 - val_accuracy: 1.0000\n",
            "Epoch 181/200\n",
            "30/30 - 0s - loss: 5.1896e-06 - accuracy: 1.0000 - val_loss: 8.3803e-06 - val_accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "30/30 - 0s - loss: 5.0882e-06 - accuracy: 1.0000 - val_loss: 8.1777e-06 - val_accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "30/30 - 0s - loss: 4.9949e-06 - accuracy: 1.0000 - val_loss: 8.0346e-06 - val_accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "30/30 - 0s - loss: 4.8955e-06 - accuracy: 1.0000 - val_loss: 7.8916e-06 - val_accuracy: 1.0000\n",
            "Epoch 185/200\n",
            "30/30 - 0s - loss: 4.8041e-06 - accuracy: 1.0000 - val_loss: 7.7426e-06 - val_accuracy: 1.0000\n",
            "Epoch 186/200\n",
            "30/30 - 0s - loss: 4.7088e-06 - accuracy: 1.0000 - val_loss: 7.6234e-06 - val_accuracy: 1.0000\n",
            "Epoch 187/200\n",
            "30/30 - 0s - loss: 4.6213e-06 - accuracy: 1.0000 - val_loss: 7.4684e-06 - val_accuracy: 1.0000\n",
            "Epoch 188/200\n",
            "30/30 - 0s - loss: 4.5359e-06 - accuracy: 1.0000 - val_loss: 7.3194e-06 - val_accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "30/30 - 0s - loss: 4.4564e-06 - accuracy: 1.0000 - val_loss: 7.1823e-06 - val_accuracy: 1.0000\n",
            "Epoch 190/200\n",
            "30/30 - 0s - loss: 4.3670e-06 - accuracy: 1.0000 - val_loss: 7.0571e-06 - val_accuracy: 1.0000\n",
            "Epoch 191/200\n",
            "30/30 - 0s - loss: 4.2856e-06 - accuracy: 1.0000 - val_loss: 6.9379e-06 - val_accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "30/30 - 0s - loss: 4.2021e-06 - accuracy: 1.0000 - val_loss: 6.7770e-06 - val_accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "30/30 - 0s - loss: 4.1207e-06 - accuracy: 1.0000 - val_loss: 6.6697e-06 - val_accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "30/30 - 0s - loss: 4.0471e-06 - accuracy: 1.0000 - val_loss: 6.5326e-06 - val_accuracy: 1.0000\n",
            "Epoch 195/200\n",
            "30/30 - 0s - loss: 3.9637e-06 - accuracy: 1.0000 - val_loss: 6.4253e-06 - val_accuracy: 1.0000\n",
            "Epoch 196/200\n",
            "30/30 - 0s - loss: 3.8922e-06 - accuracy: 1.0000 - val_loss: 6.3002e-06 - val_accuracy: 1.0000\n",
            "Epoch 197/200\n",
            "30/30 - 0s - loss: 3.8266e-06 - accuracy: 1.0000 - val_loss: 6.1929e-06 - val_accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "30/30 - 0s - loss: 3.7451e-06 - accuracy: 1.0000 - val_loss: 6.0618e-06 - val_accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "30/30 - 0s - loss: 3.6796e-06 - accuracy: 1.0000 - val_loss: 5.9783e-06 - val_accuracy: 1.0000\n",
            "Epoch 200/200\n",
            "30/30 - 0s - loss: 3.6120e-06 - accuracy: 1.0000 - val_loss: 5.8531e-06 - val_accuracy: 1.0000\n",
            "{'loss': [0.6904593110084534, 0.6628397703170776, 0.5629850625991821, 0.3728117048740387, 0.1897698938846588, 0.08498779684305191, 0.03780039772391319, 0.02063901349902153, 0.012950022704899311, 0.009038669057190418, 0.0065657151862978935, 0.0050805555656552315, 0.004044291563332081, 0.0033053522929549217, 0.0027419168036431074, 0.0023193368688225746, 0.001987460535019636, 0.0017266941722482443, 0.0015117856673896313, 0.0013330858200788498, 0.0011863865656778216, 0.0010634205536916852, 0.0009562346385791898, 0.0008664901251904666, 0.0007895910530351102, 0.0007192148477770388, 0.0006597480969503522, 0.0006072436808608472, 0.0005610800581052899, 0.000519162102136761, 0.00048079952830448747, 0.0004479541094042361, 0.0004176120855845511, 0.00039082212606444955, 0.00036605953937396407, 0.0003434133541304618, 0.00032253575045615435, 0.00030395088833756745, 0.0002866964787244797, 0.00027051419601775706, 0.00025601565721444786, 0.0002426629507681355, 0.0002297945466125384, 0.0002181573654524982, 0.00020738800230901688, 0.00019744278688449413, 0.00018792053742799908, 0.0001793376140994951, 0.00017094537906814367, 0.00016322046576533467, 0.0001562025718158111, 0.00014932171325199306, 0.0001430088304914534, 0.0001369740639347583, 0.00013126507110428065, 0.00012597112799994648, 0.0001209671754622832, 0.0001162373591796495, 0.00011164458555867895, 0.00010743314487626776, 0.0001033428925438784, 9.9544609838631e-05, 9.58853997872211e-05, 9.237914491677657e-05, 8.90576047822833e-05, 8.595654071541503e-05, 8.293891733046621e-05, 8.006035932339728e-05, 7.734864630037919e-05, 7.471242133760825e-05, 7.224702858366072e-05, 6.990877591306344e-05, 6.755860522389412e-05, 6.544482312165201e-05, 6.33230956736952e-05, 6.130663678050041e-05, 5.944316944805905e-05, 5.7532000937499106e-05, 5.5805594456614926e-05, 5.408712604548782e-05, 5.2473958930931985e-05, 5.091440834803507e-05, 4.9378704716218635e-05, 4.794829146703705e-05, 4.6553646825486794e-05, 4.521858136286028e-05, 4.392127084429376e-05, 4.266766336513683e-05, 4.146173523622565e-05, 4.035116944578476e-05, 3.9200862374855205e-05, 3.814592491835356e-05, 3.707508585648611e-05, 3.609563282225281e-05, 3.5110217140754685e-05, 3.4180433431174606e-05, 3.3264550438616425e-05, 3.2398340408690274e-05, 3.156589809805155e-05, 3.0715575121575966e-05, 2.9952669137855992e-05, 2.9177845135563985e-05, 2.843281254172325e-05, 2.771559593384154e-05, 2.701825178519357e-05, 2.6338784664403647e-05, 2.5695082513266243e-05, 2.5061310225282796e-05, 2.4441442292300053e-05, 2.3841444999561645e-05, 2.3253367544384673e-05, 2.269707511004526e-05, 2.2158657884574495e-05, 2.1624220607918687e-05, 2.1105674022692256e-05, 2.0601040887413546e-05, 2.0124216462136246e-05, 1.9651368347695097e-05, 1.918845191539731e-05, 1.8751363313640468e-05, 1.831824738474097e-05, 1.788910412869882e-05, 1.749175316945184e-05, 1.708644958853256e-05, 1.6701013009878807e-05, 1.631558006920386e-05, 1.5952000467223115e-05, 1.5588422684231773e-05, 1.5246695511450525e-05, 1.4904971976648085e-05, 1.4579139133275021e-05, 1.4259267118177377e-05, 1.3937407857156359e-05, 1.3645351828017738e-05, 1.3349324035516474e-05, 1.3049318113189656e-05, 1.2763221093337052e-05, 1.2496992894739378e-05, 1.2232749213580973e-05, 1.1958573850279208e-05, 1.1702278243319597e-05, 1.1455917046987452e-05, 1.1215514859941322e-05, 1.0977099918818567e-05, 1.0750606634246651e-05, 1.0516163456486538e-05, 1.0317485248378944e-05, 1.0085030226036906e-05, 9.880391189653892e-06, 9.671776751929428e-06, 9.475085789745208e-06, 9.26845950743882e-06, 9.08368565433193e-06, 8.896929102775175e-06, 8.718116077943705e-06, 8.541292118025012e-06, 8.368440830963664e-06, 8.19161596155027e-06, 8.030683602555655e-06, 7.863794053264428e-06, 7.722731425019447e-06, 7.561800885014236e-06, 7.406830263789743e-06, 7.265767180797411e-06, 7.1127824412542395e-06, 6.973707058932632e-06, 6.834631221863674e-06, 6.7134360506315716e-06, 6.560453584825154e-06, 6.435283921746304e-06, 6.318061878118897e-06, 6.192893579282099e-06, 6.067725280445302e-06, 5.94653056396055e-06, 5.83924384045531e-06, 5.72003500565188e-06, 5.598839834419778e-06, 5.503472948475974e-06, 5.400159352575429e-06, 5.284924100124044e-06, 5.18955721418024e-06, 5.088229954708368e-06, 4.994850769435288e-06, 4.8955103011394385e-06, 4.804117452295031e-06, 4.708751475845929e-06, 4.621330845111515e-06, 4.535897460300475e-06, 4.456424903764855e-06, 4.36701839134912e-06, 4.28556086262688e-06, 4.2021138142445125e-06, 4.120655376027571e-06, 4.04714319302002e-06, 3.9636970541323535e-06, 3.892172117048176e-06, 3.826606643997366e-06, 3.7451479784067487e-06, 3.6795836422243156e-06, 3.612031832744833e-06], 'accuracy': [0.5166666507720947, 0.6333333253860474, 0.9333333373069763, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [0.6865657567977905, 0.6423715353012085, 0.5076583623886108, 0.3071101903915405, 0.14769884943962097, 0.06548099219799042, 0.035450153052806854, 0.020875338464975357, 0.01409289799630642, 0.010083909146487713, 0.007999420166015625, 0.006382823921740055, 0.005129849538207054, 0.004202668089419603, 0.003532357979565859, 0.0030654766596853733, 0.0026619082782417536, 0.002319191349670291, 0.0020301893819123507, 0.0018215650925412774, 0.00163909827824682, 0.0014678037259727716, 0.0013379253214225173, 0.0012141556944698095, 0.0011012328322976828, 0.0010189306922256947, 0.0009461999870836735, 0.0008748358814045787, 0.0008014327613636851, 0.0007402789196930826, 0.0006949682137928903, 0.0006495370762422681, 0.0006122764898464084, 0.0005689201061613858, 0.0005330673884600401, 0.0005012140609323978, 0.0004730336950160563, 0.00044492376036942005, 0.00042183828190900385, 0.0004004200454801321, 0.00037917413283139467, 0.0003565997467376292, 0.00034131406573578715, 0.00032386070233769715, 0.00030861652339808643, 0.0002929671318270266, 0.0002807840355671942, 0.00026766565861180425, 0.00025591731537133455, 0.00024542564642615616, 0.00023367693938780576, 0.00022417391301132739, 0.00021573714911937714, 0.00020641865557990968, 0.0001983631227631122, 0.0001901228097267449, 0.00018282371456734836, 0.00017511947953607887, 0.00016876761219464242, 0.00016204631538130343, 0.00015663575322832912, 0.00015131452528294176, 0.00014497445954475552, 0.0001398378808517009, 0.00013544611283577979, 0.00013110197323840111, 0.0001261619763681665, 0.00012183569924673066, 0.00011783710215240717, 0.00011433308100095019, 0.00011040598474210128, 0.00010656229278538376, 0.00010392822878202423, 0.00010012027632910758, 9.719420631881803e-05, 9.464356844546273e-05, 9.118714660871774e-05, 8.839216025080532e-05, 8.611561497673392e-05, 8.355899626621976e-05, 8.093084034044296e-05, 7.84635849413462e-05, 7.629429455846548e-05, 7.40415562177077e-05, 7.19616436981596e-05, 6.981617480050772e-05, 6.784947618143633e-05, 6.609135743929073e-05, 6.426768231904134e-05, 6.258107168832794e-05, 6.0900416428921744e-05, 5.893966954317875e-05, 5.759870327892713e-05, 5.6114706239895895e-05, 5.456514918478206e-05, 5.308711115503684e-05, 5.1865332352463156e-05, 5.04468844155781e-05, 4.90820748382248e-05, 4.796756911673583e-05, 4.687094406108372e-05, 4.5553799282060936e-05, 4.441545024747029e-05, 4.3426094634924084e-05, 4.222217830829322e-05, 4.13281777582597e-05, 4.0273262129630893e-05, 3.9200462197186425e-05, 3.825877865892835e-05, 3.744225614354946e-05, 3.653037128970027e-05, 3.570192347979173e-05, 3.47483110090252e-05, 3.391390782780945e-05, 3.318677772767842e-05, 3.244772960897535e-05, 3.163119254168123e-05, 3.09696260956116e-05, 3.021864904440008e-05, 2.9491517125279643e-05, 2.881802174670156e-05, 2.822200804075692e-05, 2.7596190193435177e-05, 2.6940577299683355e-05, 2.641608261910733e-05, 2.5796229238039814e-05, 2.5200211894116364e-05, 2.4669756385264918e-05, 2.4115459382301196e-05, 2.357904304517433e-05, 2.3018783394945785e-05, 2.2613490727962926e-05, 2.2166475901030935e-05, 2.161217707907781e-05, 2.123668309650384e-05, 2.069430411211215e-05, 2.02949668164365e-05, 1.9847950170515105e-05, 1.940093352459371e-05, 1.900159622891806e-05, 1.8643982912180945e-05, 1.8274446119903587e-05, 1.7863190805655904e-05, 1.7535376173327677e-05, 1.7147960534202866e-05, 1.6820144082885236e-05, 1.635524313314818e-05, 1.6092992154881358e-05, 1.572941619087942e-05, 1.544332189951092e-05, 1.5127427104744129e-05, 1.4823453966528177e-05, 1.45135172715527e-05, 1.415590122633148e-05, 1.389960652886657e-05, 1.3637354641105048e-05, 1.3416822184808552e-05, 1.3154569387552328e-05, 1.2850594430346973e-05, 1.2624101145775057e-05, 1.2361849258013535e-05, 1.2123435226385482e-05, 1.1902903679583687e-05, 1.1610847650445066e-05, 1.139627602242399e-05, 1.1151902072015218e-05, 1.0961170119117014e-05, 1.0740639481809922e-05, 1.0549910257395823e-05, 1.0371099961048458e-05, 1.0186329745920375e-05, 9.930033229466062e-06, 9.769103598955553e-06, 9.572412636771332e-06, 9.381680683873128e-06, 9.184989721688908e-06, 9.059823241841514e-06, 8.863131370162591e-06, 8.70220083015738e-06, 8.529350452590734e-06, 8.38034065964166e-06, 8.17768886918202e-06, 8.034639904508367e-06, 7.891590939834714e-06, 7.742582056380343e-06, 7.623374585818965e-06, 7.468403964594472e-06, 7.319395081140101e-06, 7.182307399489218e-06, 7.057139100652421e-06, 6.937932084838394e-06, 6.7770006353384815e-06, 6.669714821327943e-06, 6.532626230182359e-06, 6.425338597182417e-06, 6.30017029834562e-06, 6.192883120093029e-06, 6.061754447728163e-06, 5.978309673082549e-06, 5.85314046475105e-06], 'val_accuracy': [0.44999998807907104, 0.699999988079071, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 5.3823e-06 - accuracy: 1.0000\n",
            "loss, accuracy= [5.382274139265064e-06, 1.0]\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.2484e-06 - accuracy: 1.0000\n",
            "loss, accuracy= [5.382274139265064e-06, 1.0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
            "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "It cost 16.403723 sec\n",
            "16.403723001480103\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmtpB_428F3w"
      },
      "source": [
        "性能1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 709
        },
        "id": "BPO3pBsg8I-E",
        "outputId": "994f0c21-9b95-4851-c634-57ed4597c1b7"
      },
      "source": [
        "def show_train_history(train_history, train, validation):  # 訓練集驗證準確度對epoch做圖\r\n",
        "    plt.plot(train_history.history[train])  # 绘制训练数据的执行结果\r\n",
        "    plt.plot(train_history.history[validation])  # 绘制验证数据的执行结果\r\n",
        "    plt.title('Train History')  # 图标题\r\n",
        "    plt.xlabel('epoch')  # x轴标签\r\n",
        "    plt.ylabel(train)  # y轴标签\r\n",
        "    plt.legend(['train', 'validation'], loc='upper left')  # 添加左上角图例\r\n",
        "    plt.show()\r\n",
        "\r\n",
        "show_train_history(train_history, 'accuracy', 'val_accuracy')\r\n",
        "\r\n",
        "show_train_history(train_history, 'loss', 'val_loss')\r\n",
        "\r\n",
        "print(pd.crosstab(y_test_label,prediction,rownames=['label'],colnames=['predict']))\r\n",
        "\r\n",
        "print(pd.crosstab(y_2,prediction2,rownames=['label'],colnames=['predict']))   # https://zhuanlan.zhihu.com/p/52368125  其他呈現交叉表方法(平均、彩色圖...)X_2,y_Test2   y_test_label,prediction\r\n",
        "\r\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "predict   0  1\n",
            "label         \n",
            "0        12  0\n",
            "1         0  8\n",
            "predict  0  1\n",
            "label        \n",
            "0        4  0\n",
            "1        0  4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtLsaVmu9Gux"
      },
      "source": [
        "性能2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhkYexmJbSAM"
      },
      "source": [
        "https://ithelp.ithome.com.tw/articles/10222697\r\n",
        "\r\n",
        "precision = true positive(tp)/true positive(TP) + false positive(FP) 預測正例的數量中，有多少是預測正確的(FN不重要(正例預測成反例不重要)(ex:正例是沒病毒，沒病毒也戴口罩、正例是晴天，晴天帶雨傘)(反例比較重要))\r\n",
        "\r\n",
        "recall = true positive(tp)/true positive(tp)+false negative(fn) 真實是正例的數量中，有多少是預測正確的(FP不重要(反例預測成正例不重要)(ex:正例是有病毒，沒病毒也戴口罩、正例是雨天，晴天帶雨傘)(正例比較重要))\r\n",
        "\r\n",
        "macro avg = 上面的column平均\r\n",
        "\r\n",
        "weighted avg = 上面的column加權平均\r\n",
        "\r\n",
        "support = 樣本數量\r\n",
        "\r\n",
        "f1-score = 2 * PR / P + R = TP / TP + (FN + FP / 2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQRELZlibSRD",
        "outputId": "67947a8b-b4f6-41e6-f629-b7fe5191db89"
      },
      "source": [
        "# Print the precision and recall, among other metrics\r\n",
        "print(metrics.classification_report(y_test_label, prediction,digits=3))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      1.000     1.000     1.000         3\n",
            "           1      1.000     1.000     1.000         5\n",
            "           2      1.000     1.000     1.000        52\n",
            "\n",
            "    accuracy                          1.000        60\n",
            "   macro avg      1.000     1.000     1.000        60\n",
            "weighted avg      1.000     1.000     1.000        60\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsxFmHmwFnCx"
      },
      "source": [
        "https://blog.csdn.net/xtingjie/article/details/72803029?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-2.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-2.control\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKu7JxN1FnL-",
        "outputId": "dd17e911-8ee3-4b39-995a-dd5c716d23a5"
      },
      "source": [
        "from sklearn.metrics import cohen_kappa_score\r\n",
        "\r\n",
        "# kappa\r\n",
        "kappa = cohen_kappa_score(y_test_label, prediction)\r\n",
        "print('Cohens kappa: %f' % kappa)\r\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cohens kappa: 1.000000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
